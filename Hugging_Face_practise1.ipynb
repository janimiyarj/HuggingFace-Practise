{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qnlp8PLKK2Z1"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0jfaGg4MBrz",
        "outputId": "07246619-eea5-4d00-91b2-f5027ff91f15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.45.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall TensorFlow and transformers\n",
        "!pip uninstall -y tensorflow transformers\n",
        "\n",
        "# Reinstall the latest versions\n",
        "!pip install tensorflow transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nSTFoMANMZQV",
        "outputId": "7de985f6-9ff8-400b-b60d-d0d05304508e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.17.0\n",
            "Uninstalling tensorflow-2.17.0:\n",
            "  Successfully uninstalled tensorflow-2.17.0\n",
            "Found existing installation: transformers 4.45.1\n",
            "Uninstalling transformers-4.45.1:\n",
            "  Successfully uninstalled transformers-4.45.1\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "Using cached transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
            "Installing collected packages: transformers, tensorflow\n",
            "Successfully installed tensorflow-2.17.0 transformers-4.45.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow",
                  "transformers"
                ]
              },
              "id": "d381302ce26b498dac5526988865b68c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextGenerationPipeline"
      ],
      "metadata": {
        "id": "JzejHmmtM3lH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EChlLiUWOozc",
        "outputId": "6467414e-a49a-4a4e-fd7e-21ac0b403ab5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example 1\n",
        "pipeline(task=\"sentiment-analysis\")(\"Love this!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpSgNgtVOs2y",
        "outputId": "a6119014-bd0f-40c1-9b96-88620341ade6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998745918273926}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(task=\"text-generation\")(\"I love this!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h16xpkXO99N",
        "outputId": "e4f181fe-3125-4527-9c1d-c9d5d7233e91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'I love this!\\n\\nClick here for more amazing, amazing reviews'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(task='sentiment-analysis')('I hate this')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8VBlTRcPEVn",
        "outputId": "fa1a7163-4816-44cb-bcba-f7b03987dbd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9996224641799927}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example 2\n",
        "pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")(\"Love this!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TTe627LPSbB",
        "outputId": "fd8ae966-9815-43c0-ca7d-7a0847041220"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998745918273926}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(task='sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
        "classifier('I Love Jani so much')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI8j5c1oPdAP",
        "outputId": "8fd8c23b-98d0-4639-d89f-dfbc74095280"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.999836802482605}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['I love Jani', 'Hey Jani will you marry me', 'You are so cute', 'Sadness is not permanent', 'Keep smiling']\n",
        "classifier(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osi48hHoPrn4",
        "outputId": "b44ac2f3-c7dc-4323-e756-9ea6827e0723"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998189806938171},\n",
              " {'label': 'POSITIVE', 'score': 0.9995400905609131},\n",
              " {'label': 'POSITIVE', 'score': 0.9998759031295776},\n",
              " {'label': 'NEGATIVE', 'score': 0.999503493309021},\n",
              " {'label': 'POSITIVE', 'score': 0.999873161315918}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if there are multiple target labels, we can return them all\n",
        "classifier2 = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbihdk-eP4KI",
        "outputId": "b2d450c8-0b77-406b-ccd9-1b2a25abd379"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0])\n",
        "classifier2(text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkib3CzAQCfC",
        "outputId": "31d02619-e2f9-470f-ad22-a0f495173bb8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love Jani\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'love', 'score': 0.9480230212211609},\n",
              "  {'label': 'admiration', 'score': 0.029652366414666176},\n",
              "  {'label': 'approval', 'score': 0.018160102888941765},\n",
              "  {'label': 'neutral', 'score': 0.013598968274891376},\n",
              "  {'label': 'joy', 'score': 0.010165070183575153},\n",
              "  {'label': 'optimism', 'score': 0.005704294890165329},\n",
              "  {'label': 'gratitude', 'score': 0.005286517087370157},\n",
              "  {'label': 'desire', 'score': 0.004773849621415138},\n",
              "  {'label': 'annoyance', 'score': 0.004760033916682005},\n",
              "  {'label': 'realization', 'score': 0.004381654318422079},\n",
              "  {'label': 'sadness', 'score': 0.003962723538279533},\n",
              "  {'label': 'disapproval', 'score': 0.003911451902240515},\n",
              "  {'label': 'excitement', 'score': 0.003785570850595832},\n",
              "  {'label': 'anger', 'score': 0.003777991747483611},\n",
              "  {'label': 'caring', 'score': 0.003709773998707533},\n",
              "  {'label': 'disappointment', 'score': 0.0035465944092720747},\n",
              "  {'label': 'amusement', 'score': 0.0032373033463954926},\n",
              "  {'label': 'confusion', 'score': 0.0023262922186404467},\n",
              "  {'label': 'disgust', 'score': 0.0019142458913847804},\n",
              "  {'label': 'curiosity', 'score': 0.0016530975699424744},\n",
              "  {'label': 'surprise', 'score': 0.0015792542835697532},\n",
              "  {'label': 'remorse', 'score': 0.0013169145677238703},\n",
              "  {'label': 'fear', 'score': 0.0008110095513984561},\n",
              "  {'label': 'nervousness', 'score': 0.0005216800491325557},\n",
              "  {'label': 'embarrassment', 'score': 0.0005134905804879963},\n",
              "  {'label': 'pride', 'score': 0.00037977771717123687},\n",
              "  {'label': 'grief', 'score': 0.00037693261401727796},\n",
              "  {'label': 'relief', 'score': 0.00034713608329184353}]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdP5FsIGQI05",
        "outputId": "9ea3ff43-d46f-4747-f2cc-f77fc3745b30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_text = '''\n",
        "His visit wasn’t planned. Yet when she saw the car pull up, riding the cusp of a tempest, Eve was unsurprised. Headlights sweeping up her driveway in this remote, vast space they called home could have been reason for fear, panic or, at the very least, an unsettling unease. But looking up from the sink, where she stood carefully drying a crystal wine glass, seeing the lights, she immediately knew. Rafe was behind her in a second, all agitation and tension, hating surprises, hating things out of his control.\n",
        "\n",
        "‘Who on earth can this be at such an hour, and in this weather,’ he complained, fiddling with his wedding ring, a subconscious action he did in the vicinity of her father, betraying that he, too, knew the identity of their guest. Her eyes glanced at the clock on the wall. The clock her father had given her. Swiss, reliable, punctual; the context for Rafe’s question. Nine thirty. Winter had tricked them into feeling it was later than it was. Nine thirty. There were nights, she remembered them like they were a fleeting dream, they would be emerging at nine thirty, to see where the evening took them. When they lived in the city. Before Zach.\n",
        "\n",
        "‘It’s Papa,’ she told him, calmly.\n",
        "\n",
        "‘He told you he’s coming?’ Rafe asked, in his sharp, unmistakable tone of annoyance.\n",
        "\n",
        "‘No,’ she said, meeting his tone with her own, breezy one.\n",
        "\n",
        "‘Then how do you know it’s him?’ Rafe squinted out into the drive. The car had cut its lights. Darkness clothed it; make and model lost to the navy depths of the outside world. Its inhabitant sitting inside, their identity not yet revealed.\n",
        "\n",
        "‘I just do,’ she replied. And she did. Of course it was him. Of course he’d come here. After everything that had happened, where else could he go?\n",
        "\n",
        "Placing the wine glass carefully on the sideboard, she moved towards the door, noting with concealed amusement Rafe’s obsessive tidiness as her other senses read what her eyes couldn’t see - him picking up the glass and returning it to the place it belonged, hanging above the island in the middle of the kitchen. Even with a surprise guest, even with the only people here being family, he couldn’t bear for one facet of the house to be out of place.\n",
        "'''\n",
        "print(dummy_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6y0bwq2QTEJ",
        "outputId": "67aae9b4-7beb-455b-dd81-718d454c576f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "His visit wasn’t planned. Yet when she saw the car pull up, riding the cusp of a tempest, Eve was unsurprised. Headlights sweeping up her driveway in this remote, vast space they called home could have been reason for fear, panic or, at the very least, an unsettling unease. But looking up from the sink, where she stood carefully drying a crystal wine glass, seeing the lights, she immediately knew. Rafe was behind her in a second, all agitation and tension, hating surprises, hating things out of his control. \n",
            "\n",
            "‘Who on earth can this be at such an hour, and in this weather,’ he complained, fiddling with his wedding ring, a subconscious action he did in the vicinity of her father, betraying that he, too, knew the identity of their guest. Her eyes glanced at the clock on the wall. The clock her father had given her. Swiss, reliable, punctual; the context for Rafe’s question. Nine thirty. Winter had tricked them into feeling it was later than it was. Nine thirty. There were nights, she remembered them like they were a fleeting dream, they would be emerging at nine thirty, to see where the evening took them. When they lived in the city. Before Zach. \n",
            "\n",
            "‘It’s Papa,’ she told him, calmly. \n",
            "\n",
            "‘He told you he’s coming?’ Rafe asked, in his sharp, unmistakable tone of annoyance. \n",
            "\n",
            "‘No,’ she said, meeting his tone with her own, breezy one.\n",
            "\n",
            "‘Then how do you know it’s him?’ Rafe squinted out into the drive. The car had cut its lights. Darkness clothed it; make and model lost to the navy depths of the outside world. Its inhabitant sitting inside, their identity not yet revealed.\n",
            "\n",
            "‘I just do,’ she replied. And she did. Of course it was him. Of course he’d come here. After everything that had happened, where else could he go?\n",
            "\n",
            "Placing the wine glass carefully on the sideboard, she moved towards the door, noting with concealed amusement Rafe’s obsessive tidiness as her other senses read what her eyes couldn’t see - him picking up the glass and returning it to the place it belonged, hanging above the island in the middle of the kitchen. Even with a surprise guest, even with the only people here being family, he couldn’t bear for one facet of the house to be out of place.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer(dummy_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fNSdAavQsb9",
        "outputId": "c00082c7-badc-45e0-803c-5164ca441fb7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'Eve was unsurprised when she saw the car pull up in her driveway. Of course he’d come here. After everything that had happened, where else could he go? Rafe squinted out into the drive. The car had cut its lights. Its inhabitant sitting inside, their identity not yet revealed.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_text = summarizer(dummy_text, min_length=5, max_length=140)[0]['summary_text']\n",
        "summarized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_WyUth-bQv9Z",
        "outputId": "725143f0-317d-4b27-80bc-8800109b21b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Eve was unsurprised when she saw the car pull up in her driveway. Of course he’d come here. After everything that had happened, where else could he go?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2(summarized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n16cc8OQ9zT",
        "outputId": "0535e043-7a71-4f61-ba1a-b08fe5436f19"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'surprise', 'score': 0.5563771724700928},\n",
              "  {'label': 'curiosity', 'score': 0.29345834255218506},\n",
              "  {'label': 'neutral', 'score': 0.23893974721431732},\n",
              "  {'label': 'confusion', 'score': 0.0542113222181797},\n",
              "  {'label': 'realization', 'score': 0.024678032845258713},\n",
              "  {'label': 'approval', 'score': 0.023227335885167122},\n",
              "  {'label': 'excitement', 'score': 0.02156778797507286},\n",
              "  {'label': 'admiration', 'score': 0.012838747352361679},\n",
              "  {'label': 'optimism', 'score': 0.010419641621410847},\n",
              "  {'label': 'disappointment', 'score': 0.007705193478614092},\n",
              "  {'label': 'annoyance', 'score': 0.005236493423581123},\n",
              "  {'label': 'joy', 'score': 0.00402649724856019},\n",
              "  {'label': 'disapproval', 'score': 0.00380427367053926},\n",
              "  {'label': 'love', 'score': 0.003383239731192589},\n",
              "  {'label': 'fear', 'score': 0.0027322466485202312},\n",
              "  {'label': 'sadness', 'score': 0.0021357028745114803},\n",
              "  {'label': 'caring', 'score': 0.0017941062105819583},\n",
              "  {'label': 'embarrassment', 'score': 0.001778503181412816},\n",
              "  {'label': 'nervousness', 'score': 0.0016789358342066407},\n",
              "  {'label': 'desire', 'score': 0.0016678227111697197},\n",
              "  {'label': 'anger', 'score': 0.001610958599485457},\n",
              "  {'label': 'amusement', 'score': 0.001239954261109233},\n",
              "  {'label': 'relief', 'score': 0.0012068586656823754},\n",
              "  {'label': 'grief', 'score': 0.0010314711835235357},\n",
              "  {'label': 'gratitude', 'score': 0.00095760403200984},\n",
              "  {'label': 'disgust', 'score': 0.0009318733937107027},\n",
              "  {'label': 'remorse', 'score': 0.0007797843427397311},\n",
              "  {'label': 'pride', 'score': 0.0005220307502895594}]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YINY9kwmRWDi",
        "outputId": "ccafd402-18c9-4d7e-aea5-65546b6ece17"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(\"Hi I'm Jani, how are you?\")"
      ],
      "metadata": {
        "id": "Q-Ee7dZERZMP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33nh5K-sRg4T",
        "outputId": "e646304e-4ac7-4241-aed8-293a31d55c04"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \" Hi jani, I'm doing well. How are you doing this fine evening?\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = chatbot(\"Where do you work?\")"
      ],
      "metadata": {
        "id": "1B2z9UjFRlWJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmMCVnClRqiG",
        "outputId": "d1cb1133-de11-4b73-b467-afc7ddf25d74"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \" I work at a grocery store as a cashier. It's not the most exciting job in the world, but it pays the bills.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top3_text_classes(message, history):\n",
        "    # Get the predictions from the classifier\n",
        "    predictions = classifier(message)\n",
        "\n",
        "    # Extract the top 3 predictions\n",
        "    top_3 = predictions[:3]\n",
        "\n",
        "    # Convert the predictions to a readable format\n",
        "    formatted_output = \"\\n\".join([f\"Label: {pred['label']}, Score: {pred['score']:.2f}\" for pred in top_3])\n",
        "\n",
        "    return formatted_output\n",
        "\n",
        "# Create a Gradio ChatInterface for sentiment analysis\n",
        "demo_sentiment = gr.ChatInterface(\n",
        "    fn=top3_text_classes,\n",
        "    title=\"Text Sentiment Chatbot\",\n",
        "    description=\"Enter your text, and the chatbot will classify the sentiment.\"\n",
        ")\n",
        "\n",
        "# Launch the interface with debugging enabled\n",
        "demo_sentiment.launch(debug=True, share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "npG-iYMmRw1J",
        "outputId": "e877cadb-77a7-4777-81f1-9cf762bd90f6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://b3c9ca1005ad0af3cc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b3c9ca1005ad0af3cc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ca23aee5c03159f432.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://3f26920a216a8c0bb4.gradio.live\n",
            "Killing tunnel 127.0.0.1:7862 <> https://b3c9ca1005ad0af3cc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def top3_text_classes(message, history):\n",
        "    # Get the predictions from the classifier\n",
        "    #predictions = summarizer(message)\n",
        "    predictions = summarizer(message, min_length=5, max_length=140)[0]['summary_text']\n",
        "\n",
        "    return predictions #formatted_output\n",
        "\n",
        "# Create a Gradio ChatInterface for sentiment analysis\n",
        "demo_sentiment = gr.ChatInterface(\n",
        "    fn=top3_text_classes,\n",
        "    title=\"Text Summarizer Chatbot\",\n",
        "    description=\"Enter your text, and the chatbot will summarize the entire Text.\"\n",
        ")\n",
        "\n",
        "# Launch the interface with debugging enabled\n",
        "demo_sentiment.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "QeRBoWNVR2xx",
        "outputId": "9f347a14-d3a2-4253-8457-b81e2f7da2b3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://b304a73134e55114cf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b304a73134e55114cf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://b304a73134e55114cf.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_list = []\n",
        "response_list = []\n",
        "\n",
        "def vanilla_chatbot(message, history):\n",
        "    conversation = chatbot(message)\n",
        "\n",
        "    return conversation[0]['generated_text']\n",
        "\n",
        "demo_chatbot = gr.ChatInterface(vanilla_chatbot, title=\"Jani Chatbot\", description=\"Enter text to start chatting with Jani.\")\n",
        "\n",
        "demo_chatbot.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "t6V1SDu6WjVH",
        "outputId": "5d042639-84bd-4fc2-ba48-27bfc19c2661"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://faddded9b617282210.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://faddded9b617282210.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jKoCkSFhYvD"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}